{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyjEVuATY40d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as TA\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from keras_preprocessing import image\n",
    "from datetime import timedelta, datetime\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTAj5f5hyrkc"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL PARAMETERS\n",
    "WINDOW = 11\n",
    "LENGTH_LIST = range(6,21)\n",
    "\n",
    "# Global Parameters CNN\n",
    "IMG_SIZE = 15\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "STEPS_EPOCH = 1260//BATCH_SIZE\n",
    "PATH_RAIZ = 'C:\\\\xxxx\\\\Documents\\\\FinancialEvaluator\\\\stocks'\n",
    "\n",
    "# Real Parameters\n",
    "START_YEAR = 2010\n",
    "LAST_YEAR = 2021\n",
    "YEAR_WINDOW = 5\n",
    "\n",
    "# Financial Evaluation Parameters\n",
    "FIN_EV_START = START_YEAR + YEAR_WINDOW\n",
    "FIN_EV_END = LAST_YEAR\n",
    "INITIAL_CAPITAL = 10000\n",
    "INITIAL_STOCKS = 0\n",
    "COST_TRADING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_acoes = [x.replace('.csv','') for x in os.listdir(r'C:\\Users\\Gush\\Documents\\USP\\Inteligencia Computacional\\Trabalho\\csv')]\n",
    "lista_acoes_dow = ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DIS', 'GE', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO',\n",
    " 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'XOM']\n",
    "lista_acoes_b3 = ['VALE3','PETR4','ITUB4','BBDC4','PETR3','BBAS3','ABEV3','ELET3','WEGE3','RENT3']\n",
    "lista_acoes_b3 = [acao+'.SA' for acao in lista_acoes_b3]\n",
    "\n",
    "lista_acoes = lista_acoes_b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacao por Fechamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAzH_Lznt-IO"
   },
   "outputs": [],
   "source": [
    "def normalizacao_por_fechamento(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    normalize_columns = ['Open','High','Low','Close']\n",
    "    for column in normalize_columns:\n",
    "        df[f'Adjusted{column}'] = df[f'{column}'] / df['Adj Close']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WaIDJ-y32Zk"
   },
   "outputs": [],
   "source": [
    "def label(row):\n",
    "    if row['Adj Close'] == row['High Window']:\n",
    "        return \"SELL\"\n",
    "    elif row['Adj Close'] == row['Low Window']:\n",
    "        return \"BUY\"\n",
    "    else:\n",
    "        return \"HOLD\"\n",
    "\n",
    "def labeling_data(df, window):\n",
    "    index = 0\n",
    "    high_window = []\n",
    "    low_window = []\n",
    "    num_columns = df.shape[0]\n",
    "    while num_columns > index:\n",
    "        maxIndex = max(list(df['Adj Close'].iloc[index:index+window]))\n",
    "        minIndex = min(list(df['Adj Close'].iloc[index:index+window]))\n",
    "        high_window.extend([maxIndex for x in range(window)])\n",
    "        low_window.extend([minIndex for x in range(window)])\n",
    "        index+=window\n",
    "\n",
    "    high_window = high_window[:num_columns]\n",
    "    low_window = low_window[:num_columns]\n",
    "    df[\"High Window\"] = pd.Series(high_window).values \n",
    "    df[\"Low Window\"] = pd.Series(low_window).values\n",
    "\n",
    "    df['Result'] = df.apply(label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKiHcDCtm0YL"
   },
   "source": [
    "## Indicadores TÃ©cnicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class PSAR:\n",
    "\n",
    "    def __init__(self, length, init_af=0.02, max_af=0.2, af_step=0.02):\n",
    "        self.max_af = max_af\n",
    "        self.init_af = init_af\n",
    "        self.af = init_af\n",
    "        self.af_step = af_step\n",
    "        self.extreme_point = None\n",
    "        self.high_price_trend = []\n",
    "        self.low_price_trend = []\n",
    "        self.high_price_window = deque(maxlen=length)\n",
    "        self.low_price_window = deque(maxlen=length)\n",
    "\n",
    "        # Lists to track results\n",
    "        self.psar_list = []\n",
    "        self.af_list = []\n",
    "        self.ep_list = []\n",
    "        self.high_list = []\n",
    "        self.low_list = []\n",
    "        self.trend_list = []\n",
    "        self._num_days = 0\n",
    "\n",
    "    def calcPSAR(self, high, low):\n",
    "        if self._num_days >= 3:\n",
    "            psar = self._calcPSAR()\n",
    "        else:\n",
    "            psar = self._initPSARVals(high, low)\n",
    "\n",
    "        psar = self._updateCurrentVals(psar, high, low)\n",
    "        self._num_days += 1\n",
    "\n",
    "        return psar\n",
    "\n",
    "    def _initPSARVals(self, high, low):\n",
    "        if len(self.low_price_window) <= 1:\n",
    "            self.trend = None\n",
    "            self.extreme_point = high\n",
    "            return None\n",
    "\n",
    "        if self.high_price_window[0] < self.high_price_window[1]:\n",
    "            self.trend = 1\n",
    "            psar = min(self.low_price_window)\n",
    "            self.extreme_point = max(self.high_price_window)\n",
    "        else: \n",
    "            self.trend = 0\n",
    "            psar = max(self.high_price_window)\n",
    "            self.extreme_point = min(self.low_price_window)\n",
    "\n",
    "        return psar\n",
    "\n",
    "    def _calcPSAR(self):\n",
    "        prev_psar = self.psar_list[-1]\n",
    "        if self.trend == 1: # Up\n",
    "            psar = prev_psar + self.af * (self.extreme_point - prev_psar)\n",
    "            psar = min(psar, min(self.low_price_window))\n",
    "        else:\n",
    "            psar = prev_psar - self.af * (prev_psar - self.extreme_point)\n",
    "            psar = max(psar, max(self.high_price_window))\n",
    "\n",
    "        return psar\n",
    "\n",
    "    def _updateCurrentVals(self, psar, high, low):\n",
    "        if self.trend == 1:\n",
    "            self.high_price_trend.append(high)\n",
    "        elif self.trend == 0:\n",
    "            self.low_price_trend.append(low)\n",
    "\n",
    "        psar = self._trendReversal(psar, high, low)\n",
    "\n",
    "        self.psar_list.append(psar)\n",
    "        self.af_list.append(self.af)\n",
    "        self.ep_list.append(self.extreme_point)\n",
    "        self.high_list.append(high)\n",
    "        self.low_list.append(low)\n",
    "        self.high_price_window.append(high)\n",
    "        self.low_price_window.append(low)\n",
    "        self.trend_list.append(self.trend)\n",
    "\n",
    "        return psar\n",
    "\n",
    "    def _trendReversal(self, psar, high, low):\n",
    "        # Checks for reversals\n",
    "        reversal = False\n",
    "        if self.trend == 1 and psar > low:\n",
    "            self.trend = 0\n",
    "            psar = max(self.high_price_trend)\n",
    "            self.extreme_point = low\n",
    "            reversal = True\n",
    "        elif self.trend == 0 and psar < high:\n",
    "            self.trend = 1\n",
    "            psar = min(self.low_price_trend)\n",
    "            self.extreme_point = high\n",
    "            reversal = True\n",
    "\n",
    "        if reversal:\n",
    "            self.af = self.init_af\n",
    "            self.high_price_trend.clear()\n",
    "            self.low_price_trend.clear()\n",
    "        else:\n",
    "                if high > self.extreme_point and self.trend == 1:\n",
    "                    self.af = min(self.af + self.af_step, self.max_af)\n",
    "                    self.extreme_point = high\n",
    "                elif low < self.extreme_point and self.trend == 0:\n",
    "                    self.af = min(self.af + self.af_step, self.max_af)\n",
    "                    self.extreme_point = low\n",
    "\n",
    "        return psar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqqMVwgj8k7f"
   },
   "outputs": [],
   "source": [
    "class Technical_Indicators():\n",
    "    def __init__(self, df, length_list):\n",
    "        self.df = df\n",
    "        self.high = df['High']\n",
    "        self.low = df['Low']\n",
    "        self.close = df['Adj Close']\n",
    "        self.volume = df['Volume']\n",
    "        self.length_list = length_list\n",
    "\n",
    "    def calculate_rsi(self, close, length):\n",
    "        fn_roll = lambda s: s.rolling(length).mean()\n",
    "        # Get the difference in price from previous step\n",
    "        delta = close.diff()\n",
    "        # Get rid of the first row, which is NaN since it did not have a previous row to calculate the differences\n",
    "        delta = delta[1:] \n",
    "\n",
    "        # Make the positive gains (up) and negative gains (down) Series\n",
    "        up, down = delta.clip(lower=0), delta.clip(upper=0).abs()\n",
    "\n",
    "        roll_up, roll_down = fn_roll(up), fn_roll(down)\n",
    "        rs = roll_up / roll_down\n",
    "        rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "        # Avoid division-by-zero if 'roll_down' is zero\n",
    "        # This prevents inf and/or nan values.\n",
    "        rsi[:] = np.select([roll_down == 0, roll_up == 0, True], [100, 0, rsi])\n",
    "        rsi.name = 'rsi'\n",
    "\n",
    "        # Assert range\n",
    "        valid_rsi = rsi[length - 1:]\n",
    "        assert ((0 <= valid_rsi) & (valid_rsi <= 100)).all()\n",
    "        # Note: rsi[:length - 1] is excluded from above assertion because it is NaN for SMA.\n",
    "\n",
    "        return rsi\n",
    "\n",
    "    def calculate_wr(self, high, low, close, length):\n",
    "        highh = high.rolling(length).max() \n",
    "        lowl = low.rolling(length).min()\n",
    "        wr = -100 * ((highh - close) / (highh - lowl))\n",
    "        return wr\n",
    "\n",
    "    def calculate_sma(self, close, length):\n",
    "        sma_series = close.rolling(window=length).mean()\n",
    "        return sma_series\n",
    "\n",
    "    def calculate_ema(self, close, length):\n",
    "        ema_series = close.ewm(span=length, adjust=False).mean()\n",
    "        return ema_series\n",
    "\n",
    "    def calculate_wma(self, close, length):\n",
    "        wma_series = close.rolling(length).apply(lambda x: ((np.arange(length)+1)*x).sum()/(np.arange(length)+1).sum(), raw=True)\n",
    "        return wma_series\n",
    "\n",
    "    def calculate_hma(self, close, length):\n",
    "        hma_series = self.calculate_wma(self.calculate_wma(close, length//2).multiply(2).sub(self.calculate_wma(close, length)), int(np.sqrt(length)))\n",
    "        return hma_series\n",
    "\n",
    "    def calculate_tema(self, close, length):\n",
    "        tema_series = (3*self.calculate_ema(close,length) - 3*self.calculate_ema(self.calculate_ema(close,length),length)) + self.calculate_ema(self.calculate_ema(self.calculate_ema(close,length),length),length)\n",
    "        return tema_series\n",
    "\n",
    "    def calculate_cci(self, high, low, close, length):\n",
    "        # typical price\n",
    "        tp = (high + low + close) / 3\n",
    "        # simple moving average\n",
    "        sma = tp.rolling(length).mean()\n",
    "        # mean average deviation\n",
    "        mad = tp.rolling(length).apply(lambda x: pd.Series(x).mad())\n",
    "        cci_series = (tp - sma) / (0.015 * mad) \n",
    "        return cci_series\n",
    "\n",
    "    def calculate_cmo(self, close, length):\n",
    "        cmo_series = TA.cmo(close, length=length, talib=False)\n",
    "        return cmo_series\n",
    "\n",
    "    def calculate_macd(self, close, length):\n",
    "        macd_series = self.calculate_ema(close,12) - self.calculate_ema(close,26)\n",
    "        return macd_series\n",
    "\n",
    "    def calculate_ppo(self, close, length):\n",
    "        ppo_series = 100*(self.calculate_ema(close,12) - self.calculate_ema(close,26)) / self.calculate_ema(close,26)\n",
    "        return ppo_series\n",
    "\n",
    "    def calculate_roc(self, close, length):\n",
    "        latest_close = close\n",
    "        previous_close = close.shift(length)\n",
    "        roc_series = 100*(latest_close - previous_close)/(previous_close)\n",
    "        return roc_series\n",
    "\n",
    "    def _calculate_money_flow_volume_series(self, high, low, close, volume):\n",
    "        \"\"\"\n",
    "        Calculates money flow series\n",
    "        \"\"\"\n",
    "        mfv = volume * (2*close - high - low) / (high - low)\n",
    "        return mfv\n",
    "\n",
    "    def _calculate_money_flow_volume(self, high, low, close, volume, length):\n",
    "        \"\"\"\n",
    "        Calculates money flow volume, or q_t in our formula\n",
    "        \"\"\"\n",
    "        return self._calculate_money_flow_volume_series(high,low,close,volume).rolling(length).sum()\n",
    "\n",
    "    def _calculate_chaikin_money_flow(self, high, low, close, volume, length):\n",
    "        \"\"\"\n",
    "        Calculates the Chaikin money flow\n",
    "        \"\"\"\n",
    "        return self._calculate_money_flow_volume(high,low,close,volume,length) / volume.rolling(length).sum()\n",
    "\n",
    "    def calculate_cmfi(self, high, low, close, volume, length):\n",
    "        cmfi_series = self._calculate_chaikin_money_flow(high,low,close,volume,length)\n",
    "        return cmfi_series\n",
    "    \n",
    "    def calculate_dmi(self, high, low, close, period):\n",
    "        \"\"\"\n",
    "        Computes the ADX indicator.\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame({'High': high, 'Low': low, 'Close': close})\n",
    "\n",
    "        df = data.copy()\n",
    "        alpha = 1/period\n",
    "\n",
    "        # TR\n",
    "        df['H-L'] = df['High'] - df['Low']\n",
    "        df['H-C'] = np.abs(df['High'] - df['Close'].shift(1))\n",
    "        df['L-C'] = np.abs(df['Low'] - df['Close'].shift(1))\n",
    "        df['TR'] = df[['H-L', 'H-C', 'L-C']].max(axis=1)\n",
    "        del df['H-L'], df['H-C'], df['L-C']\n",
    "\n",
    "        # ATR\n",
    "        df['ATR'] = df['TR'].ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "        # +-DX\n",
    "        df['H-pH'] = df['High'] - df['High'].shift(1)\n",
    "        df['pL-L'] = df['Low'].shift(1) - df['Low']\n",
    "        df['+DX'] = np.where(\n",
    "            (df['H-pH'] > df['pL-L']) & (df['H-pH']>0),\n",
    "            df['H-pH'],\n",
    "            0.0\n",
    "        )\n",
    "        df['-DX'] = np.where(\n",
    "            (df['H-pH'] < df['pL-L']) & (df['pL-L']>0),\n",
    "            df['pL-L'],\n",
    "            0.0\n",
    "        )\n",
    "        del df['H-pH'], df['pL-L']\n",
    "\n",
    "        # +- DMI\n",
    "        df['S+DM'] = df['+DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "        df['S-DM'] = df['-DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "        df['+DMI'] = (df['S+DM']/df['ATR'])*100\n",
    "        df['-DMI'] = (df['S-DM']/df['ATR'])*100\n",
    "        del df['S+DM'], df['S-DM']\n",
    "\n",
    "        # ADX\n",
    "        df['DX'] = (np.abs(df['+DMI'] - df['-DMI'])/(df['+DMI'] + df['-DMI']))*100\n",
    "        df['ADX'] = df['DX'].ewm(alpha=alpha, adjust=False).mean()\n",
    "        del df['DX'], df['ATR'], df['TR'], df['-DX'], df['+DX'], df['+DMI'], df['-DMI']\n",
    "        \n",
    "        adx_series = df['ADX']\n",
    "        return adx_series\n",
    "    \n",
    "    def calculate_sar(self, high, low, length):\n",
    "    \n",
    "        data = pd.DataFrame({'High': high, 'Low': low})\n",
    "\n",
    "        indic = PSAR(length=length)\n",
    "        data['PSAR'] = data.apply(lambda x: indic.calcPSAR(x['High'], x['Low']), axis=1)\n",
    "        sar_series = data['PSAR']\n",
    "        return sar_series\n",
    "\n",
    "    def calculate_indicators(self):\n",
    "        for length in self.length_list:\n",
    "            self.length = length\n",
    "            self.df[f'TEC_IND_RSA_{length}_DAYS'] = self.calculate_rsi(self.close, length)\n",
    "            self.df[f'TEC_IND_WR_{length}_DAYS'] = self.calculate_wr(self.high, self.low, self.close, length)\n",
    "            self.df[f'TEC_IND_SMA_{length}_DAYS'] = self.calculate_sma(self.close, length)\n",
    "            self.df[f'TEC_IND_EMA_{length}_DAYS'] = self.calculate_ema(self.close, length)\n",
    "            self.df[f'TEC_IND_WMA_{length}_DAYS'] = self.calculate_wma(self.close, length)\n",
    "            self.df[f'TEC_IND_HMA_{length}_DAYS'] = self.calculate_hma(self.close, length)\n",
    "            self.df[f'TEC_IND_TEMA_{length}_DAYS'] = self.calculate_tema(self.close, length)\n",
    "            self.df[f'TEC_IND_CCI_{length}_DAYS'] = self.calculate_cci(self.high, self.low, self.close, length)\n",
    "            self.df[f'TEC_IND_CMO_{length}_DAYS'] = self.calculate_cmo(self.close, length)\n",
    "            self.df[f'TEC_IND_MACD_{length}_DAYS'] = self.calculate_macd(self.close, length)\n",
    "            self.df[f'TEC_IND_PPO_{length}_DAYS'] = self.calculate_ppo(self.close, length)\n",
    "            self.df[f'TEC_IND_ROC_{length}_DAYS'] = self.calculate_roc(self.close, length)\n",
    "            self.df[f'TEC_IND_CMFI_{length}_DAYS'] = self.calculate_cmfi(self.high, self.low, self.close, self.volume, length)\n",
    "            self.df[f'TEC_IND_DMI_{length}_DAYS'] = self.calculate_dmi(self.high, self.low, self.close, length)\n",
    "            self.df[f'TEC_IND_SAR_{length}_DAYS'] = self.calculate_sar(self.high, self.low, length)\n",
    "        \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2ijiQiUm4r5"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "-0yoTS1yy6GE",
    "outputId": "a897a184-2f47-4d5e-b7b6-a0f44a7ae941"
   },
   "outputs": [],
   "source": [
    "def gera_checkpoint(df,nome):\n",
    "    df.to_csv(f'{nome}.csv',sep=';',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stock(path_raiz, acao):\n",
    "    path_delecao = f'{path_raiz}\\\\{acao}'\n",
    "    shutil.rmtree(path_delecao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0NglJnErmLU"
   },
   "source": [
    "## Normalizacao dos indicadores e labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB3zo-O4GRkS"
   },
   "outputs": [],
   "source": [
    "def normalize_columns(df):\n",
    "    colunas_indicadores = [col for col in df.columns if 'TEC_IND_' in col]\n",
    "    for column in colunas_indicadores:\n",
    "        df[column] =  (df[column]-df[column].min())/(df[column].max()-df[column].min())  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBA3_ewp436y"
   },
   "source": [
    "# GeraÃ§Ã£o imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data(df, length_list):\n",
    "    all_dates = df['Date'].tolist()\n",
    "    indicators = ['RSA','WR','SMA','EMA','WMA','HMA','TEMA','CCI','CMO','MACD','PPO','ROC','CMFI','DMI','SAR']\n",
    "    length_list = length_list\n",
    "    complete_list = []\n",
    "\n",
    "    for data_individual in all_dates:\n",
    "        individual_date_dict = {}\n",
    "        individual_analyse = df[df['Date'] == data_individual]\n",
    "\n",
    "        # f'TEC_IND_{nome}_{length}_DAYS'\n",
    "        macro_list = []\n",
    "        for indicator in indicators:\n",
    "            micro_list = []\n",
    "            for length in length_list:\n",
    "                micro_list.append(individual_analyse[f'TEC_IND_{indicator}_{length}_DAYS'].iloc[0])\n",
    "            macro_list.append(micro_list)\n",
    "        y = np.array([np.array(xi) for xi in macro_list])\n",
    "        z = (y * 255).astype(np.uint8)\n",
    "\n",
    "        individual_date_dict['Date'] = data_individual\n",
    "        individual_date_dict['Image'] = z\n",
    "        individual_date_dict['Label'] = individual_analyse['Result'].tolist()[0]\n",
    "        complete_list.append(individual_date_dict)\n",
    "\n",
    "    df_images = pd.DataFrame(complete_list)\n",
    "    return df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AfixrrRNzy1"
   },
   "outputs": [],
   "source": [
    "def image_generator(df, acao):\n",
    "    all_dates = df['Date'].tolist()\n",
    "    for data in all_dates:\n",
    "        sub_df_data = df[df['Date']==data]\n",
    "        byt = sub_df_data['Image'].tolist()[0]\n",
    "        label = sub_df_data['Label'].tolist()[0]\n",
    "        ano = sub_df_data['Date'].tolist()[0].strftime('%Y')\n",
    "        full_date = sub_df_data['Date'].tolist()[0].strftime('%Y%m%d')\n",
    "        img = Image.fromarray(byt, 'L')\n",
    "        save_path = f'stocks/{acao}/{ano}/{label}'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        save_complete_path = save_path + f'/{full_date}.png'\n",
    "        #print(f'Salvando imagem {save_path_complete}')\n",
    "        img.save(save_complete_path)\n",
    "    print(f'As imagens da acao {acao} foram criadas com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhQ-e6YKoJoy"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunÃ§Ãµes para manipulaÃ§Ã£o de arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path_raiz, acao, start_year, last_year, tipo):\n",
    "    operacoes = ['BUY','SELL','HOLD']\n",
    "    range_years = range(start_year,last_year+1)\n",
    "    for year in range_years:\n",
    "        for operacao in operacoes:\n",
    "            src = f'{path_raiz}\\\\{acao}\\\\{year}\\\\{operacao}\\\\'\n",
    "            des = f'{path_raiz}\\\\{acao}\\\\{tipo}\\\\{operacao}\\\\'\n",
    "            if not os.path.exists(des):\n",
    "                os.makedirs(des)\n",
    "            # print(f'Movendo do diretorio {src} para {dest}')\n",
    "            src_files = os.listdir(src)\n",
    "            for file_name in src_files:\n",
    "                full_file_name = os.path.join(src, file_name)\n",
    "                if os.path.isfile(full_file_name):\n",
    "                    shutil.copy(full_file_name, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(path_raiz, acao, start_year_train, last_year_train, start_year_test=None, last_year_test=None):\n",
    "    # Criando treino\n",
    "    # print(f\"Criando path de treino para periodo {start_year_train}-{last_year_train}\")\n",
    "    create_dir(path_raiz, acao, start_year_train, last_year_train, 'train')\n",
    "    \n",
    "    if start_year_test is not None:\n",
    "        if last_year_test is None: \n",
    "            last_year_test = start_year_test\n",
    "\n",
    "        print(f\"Criando path de teste para periodo {start_year_test}-{last_year_test}\")\n",
    "        create_dir(path_raiz, acao, start_year_test, last_year_test, 'test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_dirs(path_raiz, acao):\n",
    "    dirs = ['train','test']\n",
    "\n",
    "    for diretorio in dirs:\n",
    "        path_delecao = f'{path_raiz}\\\\{acao}\\\\{diretorio}'\n",
    "        shutil.rmtree(path_delecao)\t\n",
    "        # print(f'Path {path_delecao} deletado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criacao da Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(img_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Primeira camada de convoluÃ§Ã£o\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 1)),\n",
    "        # Segunda camada de convoluÃ§Ã£o\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        # Max Pooling 2x2\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # Primeiro Dropout\n",
    "        tf.keras.layers.Dropout(0.25),  \n",
    "        # Camada Flatten / Fully Connected\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # Segundo Dropout\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Camada Dense\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datagenerator(path_raiz,acao,batch_size, img_size, train_or_test):\n",
    "\n",
    "    generatorImage = ImageDataGenerator(\n",
    "        rescale=1. / 255\n",
    "    )\n",
    "\n",
    "    TEST_DIR = f'{path_raiz}\\\\{acao}\\\\{train_or_test}\\\\'\n",
    "    generator = generatorImage.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(img_size,img_size),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    label_map = (generator.class_indices)\n",
    "    # print(label_map)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(path_raiz,acao,epocas,steps_per_epoch,batch_size):\n",
    "    img_size = IMG_SIZE\n",
    "    class_weight = {0: 9, 1: 1., 2: 9.}\n",
    "    model = modelo(img_size)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "    train_generator = build_datagenerator(path_raiz=path_raiz, acao=acao, batch_size=batch_size, img_size=img_size, train_or_test='train')\n",
    "    test_generator = build_datagenerator(path_raiz=path_raiz, acao=acao, batch_size=batch_size, img_size=img_size, train_or_test='test')\n",
    "    history = model.fit(train_generator, epochs=epocas, steps_per_epoch=steps_per_epoch, validation_data=test_generator, verbose=0, validation_steps=steps_per_epoch//5, class_weight=class_weight)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao(model,path):\n",
    "    img = image.load_img(path, target_size=(IMG_SIZE, IMG_SIZE),color_mode=\"grayscale\")\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    # {'BUY': 0, 'HOLD': 1, 'SELL': 2}\n",
    "    classes = model.predict(images, verbose=0)\n",
    "    # print(classes)\n",
    "    if classes[0][0] > classes[0][1] and classes[0][0] > classes[0][2]:\n",
    "        classe = 0\n",
    "        tipo = 'BUY'\n",
    "    elif classes[0][2] > classes[0][0] and classes[0][2] > classes[0][1]:\n",
    "        classe = 2\n",
    "        tipo = 'SELL'\n",
    "    else:\n",
    "        classe = 1\n",
    "        tipo = 'HOLD'\n",
    "    #print(path)\n",
    "    #print(tipo)\n",
    "    return classe, tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_evaluation(path_raiz,acao,start_year,last_year,tipo):\n",
    "    operacoes = ['BUY','SELL','HOLD']\n",
    "    range_years = range(start_year,last_year+1)\n",
    "    for year in range_years:\n",
    "        for operacao in operacoes:\n",
    "            src = f'{path_raiz}\\\\{acao}\\\\{year}\\\\{operacao}\\\\'\n",
    "            des = f'{path_raiz}\\\\{acao}\\\\{tipo}\\\\'\n",
    "            if not os.path.exists(des):\n",
    "                os.makedirs(des)\n",
    "            # print(f'Movendo do diretorio {src} para {dest}')\n",
    "            src_files = os.listdir(src)\n",
    "            for file_name in src_files:\n",
    "                full_file_name = os.path.join(src, file_name)\n",
    "                if os.path.isfile(full_file_name):\n",
    "                    shutil.copy(full_file_name, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Financial_Evaluation_Manager(df, path_raiz, acao, model, start_year, last_year, initial_capital, initial_stocks, cost_trading, last_day, preco_compra=None):\n",
    "    tipo = 'FinEv'\n",
    "    create_dir_evaluation(path_raiz=path_raiz,acao=acao,start_year=start_year,last_year=last_year,tipo=tipo)\n",
    "    df_trade = df[(df['Date'] >= f'{start_year}-01-01') & (df['Date'] <= f'{last_year}-12-31')] #.drop(['Result'],axis=1)\n",
    "    df_trade['StockPath'] = f\"{path_raiz}\\\\{acao}\\\\{tipo}\\\\\" + df['Date'].dt.strftime('%Y%m%d') +\".png\"\n",
    "    \n",
    "    status = ''\n",
    "    list_stocks = {}\n",
    "    confusion_matrix = []\n",
    "    money = initial_capital\n",
    "    stocks = initial_stocks\n",
    "    \n",
    "    print(f\"Iniciando ano de trading com {money} dÃ³lares e {stocks} aÃ§Ãµes\")\n",
    "    for index, row in df_trade.iterrows():\n",
    "        path_image = row['StockPath']\n",
    "        price_stock = row['Adj Close']\n",
    "        day = row['Date']\n",
    "        window_prediction = row['Result']\n",
    "        predicao_stock, tipo_operacao = predicao(model,path_image)\n",
    "        \n",
    "        confusion_matrix.append({'window': window_prediction, 'previsao':tipo_operacao})\n",
    "        \n",
    "        if predicao_stock == 0 and money > price_stock and status != 'COM' and stocks == 0:\n",
    "            stocks = stocks + int(money/price_stock)\n",
    "            money = money - stocks*price_stock - cost_trading\n",
    "            status = 'COM'\n",
    "            preco_compra = price_stock\n",
    "            print(f'{day} - Operacao de Compra (deveria ser {window_prediction}) - Att: Dinheiro {money} | Acoes {stocks}')\n",
    "        elif predicao_stock == 2 and stocks > 0 and status != 'SEM' and price_stock > preco_compra:\n",
    "            money = money + stocks*price_stock - cost_trading\n",
    "            stocks = 0\n",
    "            status = 'SEM'\n",
    "            preco_compra = 0\n",
    "            print(f'{day} - Operacao de Venda (deveria ser {window_prediction}) - Att: Dinheiro {money} | Acoes {stocks}')\n",
    "        \n",
    "        if last_day == day and stocks > 0:\n",
    "            print('Ultimo dia de negociaÃ§Ãµes - vendendo aÃ§Ãµes remanecentes')\n",
    "            money = money + stocks*price_stock - cost_trading\n",
    "            stocks = 0\n",
    "            status = 'SEM'\n",
    "            print(f'{day} - Operacao de Venda (deveria ser {window_prediction})- Att: Dinheiro {money} | Acoes {stocks}')\n",
    "        \n",
    "        list_stocks[day] = {'stocks':stocks,'money':money}\n",
    "\n",
    "    return list_stocks, confusion_matrix, money, stocks, preco_compra\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Manager(df, path_raiz, acao, start_year, last_year, year_window,\n",
    "                epochs, steps_epoch, batch_size, \n",
    "                initial_capital, initial_stocks, cost_trading, last_day):\n",
    "    \n",
    "    # Inicializa variaveis\n",
    "    lista_historicos = []\n",
    "    list_stocks = {}\n",
    "    list_matrix = []\n",
    "    \n",
    "    # Valores iniciais\n",
    "    start_year_train = start_year\n",
    "    last_year_train = start_year + year_window - 1\n",
    "    _capital = initial_capital\n",
    "    _stocks = initial_stocks\n",
    "    _preco_compra = None\n",
    "    \n",
    "    while last_year_train < last_year:\n",
    "        print(f\"\"\"Periodo de treino {start_year_train}-{last_year_train}\\nPerÃ­odo de teste {last_year_train+1}\"\"\")\n",
    "        \n",
    "        create_dirs(path_raiz,acao,start_year_train,last_year_train,last_year_train+1)\n",
    "\n",
    "        model, historico = CNN(path_raiz,acao,epochs,steps_epoch,batch_size)\n",
    "        lista_historicos.append(historico)\n",
    "        delete_dirs(path_raiz,acao)\n",
    "        # model.save(f'models//{acao}_ts_to_cnn.h5')\n",
    "        \n",
    "        stocks, matrix, _capital, _stocks, _preco_compra = Financial_Evaluation_Manager(df=df, path_raiz=path_raiz, acao=acao, model=model,\n",
    "                                                                       start_year=last_year_train+1, last_year=last_year_train+1, \n",
    "                                                                       initial_capital=_capital, initial_stocks=_stocks, \n",
    "                                                                       cost_trading=cost_trading, last_day=last_day, preco_compra=_preco_compra)\n",
    "        \n",
    "        list_stocks = {**list_stocks,**stocks}\n",
    "        list_matrix = [*list_matrix, *matrix]\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        start_year_train += 1\n",
    "        last_year_train += 1\n",
    "        \n",
    "    return lista_historicos, list_stocks, list_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = {}\n",
    "for acao in lista_acoes:\n",
    "    print(f\"Iniciando analise para a aÃ§Ã£o {acao} as {datetime.now().strftime('%d/%m/%y %H:%M:%S')}\")\n",
    "    try:\n",
    "        delete_stock(path_raiz=PATH_RAIZ, acao=acao)\n",
    "    except:\n",
    "        ...\n",
    "    df = yf.download(acao, start=f'{START_YEAR}-01-01', end=f'{LAST_YEAR}-12-31').reset_index()\n",
    "\n",
    "    df = normalizacao_por_fechamento(df=df)\n",
    "    dfl = labeling_data(df=df, window=WINDOW)\n",
    "    dfi = Technical_Indicators(df=dfl, length_list=LENGTH_LIST).calculate_indicators()\n",
    "    df_indicadores = dfi.copy()\n",
    "    dfn = normalize_columns(df=dfi)\n",
    "    df_images = image_data(df=dfn, length_list=LENGTH_LIST)\n",
    "    image_generator(df=df_images, acao=acao)\n",
    "\n",
    "    last_day = dfn.iloc[-1]['Date']\n",
    "\n",
    "    lista_historico, list_stocks, list_matrix = CNN_Manager(df=dfn, path_raiz=PATH_RAIZ, acao=acao, \n",
    "                                                           start_year=START_YEAR, last_year=LAST_YEAR, year_window=YEAR_WINDOW, \n",
    "                                                           epochs=EPOCHS, steps_epoch=STEPS_EPOCH, batch_size=BATCH_SIZE, \n",
    "                                                           initial_capital=INITIAL_CAPITAL, initial_stocks=INITIAL_STOCKS, cost_trading=COST_TRADING,\n",
    "                                                           last_day=last_day)\n",
    "\n",
    "    final_report[acao] = {\n",
    "        'df': df_indicadores,\n",
    "        'historico': lista_historico,\n",
    "        'stocks': list_stocks,\n",
    "        'matrix': list_matrix\n",
    "    }\n",
    "    # delete_stock(path_raiz=PATH_RAIZ, acao=acao)\n",
    "    print(f\"Finalizando analise para a aÃ§Ã£o {acao} as {datetime.now().strftime('%d/%m/%y %H:%M:%S')}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "j2ijiQiUm4r5",
    "7yrAQZG3E-KJ",
    "IiH9zbqeoz4w",
    "AhdjOPNNoKcf",
    "r0NglJnErmLU",
    "cBA3_ewp436y",
    "QhQ-e6YKoJoy"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
